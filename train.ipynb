{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# To build and train resnet, use the pytorch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d23eeffd64a04ea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from accelerate import Accelerator\n",
    "from evaluate import load\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32ab82eaf911b3a0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set device\n",
    "accelerator = Accelerator(device_placement=True)\n",
    "device = accelerator.device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a11ab87be5940bdc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "num_epochs = 200\n",
    "batch_size = 2 ** 5\n",
    "learning_rate = 0.01"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5df28acc8474caaa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "norm = transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "\n",
    "# Define data transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    norm,\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    norm,\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42e5a84ca23a9ac9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load CIFAR-100 dataset\n",
    "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f73415ebe7ccc25",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet101 model\n",
    "model = models.densenet121(weights=None)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, 100)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create the learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda x: 0.65 ** x)\n",
    "\n",
    "# Prepare for distributed training\n",
    "model, optimizer, train_dataloader, test_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, test_dataloader\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db5c6c427dc4c05f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load evaluation metrics\n",
    "accuracy = load(\"accuracy\")\n",
    "f1 = load(\"f1\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70d826dedc62abc8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    tic = datetime.now()\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for images, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_preds = []\n",
    "    test_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            test_preds.extend(accelerator.gather(preds))  #.cpu().numpy())\n",
    "            test_labels.extend(accelerator.gather(labels))  #.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_acc = accuracy.compute(references=test_labels, predictions=test_preds)[\"accuracy\"]\n",
    "    test_f1 = f1.compute(references=test_labels, predictions=test_preds, average=\"macro\")[\"f1\"]\n",
    "\n",
    "    # Update the learning rate based on validation loss\n",
    "    scheduler.step(test_loss)\n",
    "\n",
    "    # Time calculation\n",
    "    toc = datetime.now()\n",
    "    elapsed_time = toc - tic\n",
    "    elapsed_time_in_hh_mm_ss = str(elapsed_time).split('.')[0]\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, \"\n",
    "        f\"Test Accuracy: {test_acc:.4f}, Test F1: {test_f1:.4f}, \"\n",
    "        f'Elapsed Time: {elapsed_time_in_hh_mm_ss}\\n'\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a29d66f4b2a035c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
